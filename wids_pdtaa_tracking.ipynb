# ==========================================
# 1. SETUP & DATA PREPARATION
# ==========================================
import os
import json
import shutil
import pandas as pd
from google.colab import files

# --- KAGGLE CONFIGURATION ---
kaggle_creds = {
    "username": "INSERT_YOUR_USERNAME",
    "key": "INSERT_YOUR_KEY"
}

with open('kaggle.json', 'w') as f:
    json.dump(kaggle_creds, f)

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# --- DOWNLOAD DATASET ---
print("Downloading MOT17 Dataset...")
if not os.path.exists("/content/MOT17_Dataset"):
    !kaggle datasets download -d wenhoujinjust/mot-17
    !unzip -q mot-17.zip -d /content/MOT17_Dataset
print("Data Downloaded & Unzipped.")

# --- PREPROCESSING (Convert to YOLO Format) ---
base_path = "/content/MOT17_Dataset/MOT17"
output_path = "/content/yolo_mot17"
train_sequences = ['MOT17-02-FRCNN', 'MOT17-04-FRCNN', 'MOT17-05-FRCNN', 'MOT17-09-FRCNN', 'MOT17-10-FRCNN', 'MOT17-11-FRCNN', 'MOT17-13-FRCNN']

# Clear old folder if exists
if os.path.exists(output_path): shutil.rmtree(output_path)

for split in ['train', 'val']:
    os.makedirs(f"{output_path}/images/{split}", exist_ok=True)
    os.makedirs(f"{output_path}/labels/{split}", exist_ok=True)

def convert_to_yolo_bbox(bbox, w, h):
    x_center = (bbox[0] + bbox[2] / 2) / w
    y_center = (bbox[1] + bbox[3] / 2) / h
    width = bbox[2] / w
    height = bbox[3] / h
    return x_center, y_center, width, height

print(" converting Annotations to YOLO Format...")

for seq in train_sequences:
    seq_path = os.path.join(base_path, 'train', seq)
    img_dir = os.path.join(seq_path, 'img1')
    gt_file = os.path.join(seq_path, 'gt', 'gt.txt')
    ini_file = os.path.join(seq_path, 'seqinfo.ini')

    if not os.path.exists(ini_file): continue
    with open(ini_file, 'r') as f:
        info = f.read().splitlines()
        img_width = int([l for l in info if 'imWidth' in l][0].split('=')[1])
        img_height = int([l for l in info if 'imHeight' in l][0].split('=')[1])

    with open(gt_file, 'r') as f: lines = f.readlines()

    for line in lines:
        data = line.strip().split(',')
        frame_id = int(data[0])
        class_id = int(data[7])
        visibility = float(data[8])

        # Class 1 = Pedestrian, Visibility > 0.2
        if class_id == 1 and visibility > 0.2:
            bbox = [float(data[2]), float(data[3]), float(data[4]), float(data[5])]
            yolo_bbox = convert_to_yolo_bbox(bbox, img_width, img_height)

            img_name = f"{seq}_{frame_id:06d}.jpg"
            label_name = f"{seq}_{frame_id:06d}.txt"
            
            # 80/20 Train/Val Split
            split = 'train' if frame_id < (len(os.listdir(img_dir)) * 0.8) else 'val'

            with open(f"{output_path}/labels/{split}/{label_name}", 'a') as outfile:
                outfile.write(f"0 {yolo_bbox[0]} {yolo_bbox[1]} {yolo_bbox[2]} {yolo_bbox[3]}\n")

            src_img = os.path.join(img_dir, f"{frame_id:06d}.jpg")
            dst_img = os.path.join(output_path, 'images', split, img_name)
            if not os.path.exists(dst_img):
                shutil.copy(src_img, dst_img)

print("Preprocessing Complete!")

# --- CONFIG FILE ---
yaml_content = f"""
train: /content/yolo_mot17/images/train
val: /content/yolo_mot17/images/val
nc: 1
names: ['pedestrian']
"""
with open('/content/data.yaml', 'w') as f:
    f.write(yaml_content)
print("data.yaml created.")




# ==========================================
# 2. PHASE I: TRAINING (Object Detection)
# ==========================================
import os
import shutil

# --- INSTALL YOLOv5 ---
print("Installing YOLOv5...")
if os.path.exists("/content/yolov5"): shutil.rmtree("/content/yolov5")
!git clone https://github.com/ultralytics/yolov5 > /dev/null
%cd /content/yolov5
!pip install -r requirements.txt > /dev/null

# --- TRAIN MODELS ---
# We train 3 variants for comparison
print("\n Training Case 1 (YOLOv5s)...")
!python train.py --img 640 --batch 16 --epochs 5 --data /content/data.yaml --weights yolov5s.pt --name mot17_yolov5s --exist-ok

print("\n Training Case 2 (YOLOv5m)...")
!python train.py --img 640 --batch 16 --epochs 5 --data /content/data.yaml --weights yolov5m.pt --name mot17_yolov5m --exist-ok

print("\n Training Case 3 (YOLOv5m Frozen Layers)...")
!python train.py --img 640 --batch 16 --epochs 5 --data /content/data.yaml --weights yolov5m.pt --freeze 10 --name mot17_yolov5m_frozen --exist-ok

# --- EXTRACT BEST WEIGHTS ---
best_weights_path = "/content/yolov5/runs/train/mot17_yolov5m_frozen/weights/best.pt"
print(f"Training Complete. Best weights saved at: {best_weights_path}")




# ==========================================
# 3. PHASE II: TRACKING (DeepSORT / BoT-SORT)
# ==========================================
import os
from google.colab import files
from ultralytics import YOLO

# --- SETUP ---
print("Installing Tracking Libraries...")
!pip install -q ultralytics

print("\n Downloading Sample Video...")
%cd /content
if not os.path.exists("mot_sample.mp4"):
    !wget -q -O mot_sample.mp4 https://github.com/intel-iot-devkit/sample-videos/raw/master/people-detection.mp4

# --- LOAD CUSTOM MODEL ---
# We use the best weights from Phase I
custom_model_path = "/content/yolov5/runs/train/mot17_yolov5m_frozen/weights/best.pt"

print(f"⚙️ Loading Custom Model: {custom_model_path}")
if os.path.exists(custom_model_path):
    model = YOLO(custom_model_path)
else:
    print("Custom model not found. Using standard YOLOv8n as fallback.")
    model = YOLO('yolov8n.pt')

# --- RUN TRACKING ---
# classes=[0] ensures we only track People (Class 0) and ignore background noise like TVs
print("Running Tracker...")
results = model.track(
    source="mot_sample.mp4",
    save=True,
    classes=[0],       # Filter: Person Only
    conf=0.5,          # Confidence Threshold
    project="/content/runs",
    name="mot_tracking_results",
    exist_ok=True
)

print("\n Tracking Complete!")

# --- DOWNLOAD RESULT ---
import glob
video_files = glob.glob("/content/runs/mot_tracking_results/*.avi") + glob.glob("/content/runs/mot_tracking_results/*.mp4")

if video_files:
    print(f" Downloading: {video_files[0]}")
    files.download(video_files[0])
else:
    print(" Output video not found.")
